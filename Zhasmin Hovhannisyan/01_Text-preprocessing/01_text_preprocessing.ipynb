{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Lab 1: Text preprocessing using basic python",
   "id": "7ad1e9717ea596b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:39:07.972468Z",
     "start_time": "2025-09-23T05:39:07.964799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import string\n",
    "sample_text = \" Natural Language Processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language. It's used to analyze text, allowing machines to understand, interpret, and manipulate human language. NLP has many real-world applications, including machine translation, sentiment analysis, and chatbots. babies, companies \""
   ],
   "id": "627a84371ba44b4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:39:08.402766Z",
     "start_time": "2025-09-23T05:39:08.397456Z"
    }
   },
   "cell_type": "code",
   "source": "print('Original Text:', sample_text)",
   "id": "dd9d5a921d81a919",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:  Natural Language Processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language. It's used to analyze text, allowing machines to understand, interpret, and manipulate human language. NLP has many real-world applications, including machine translation, sentiment analysis, and chatbots. babies, companies \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Tokenization: split the text into individual words (tokens)",
   "id": "a6b21ba27ca18bf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:39:12.860770Z",
     "start_time": "2025-09-23T05:39:12.844631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = sample_text.split()\n",
    "tokens"
   ],
   "id": "e0268e42b61bd5b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(NLP)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics,',\n",
       " 'computer',\n",
       " 'science,',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language.',\n",
       " \"It's\",\n",
       " 'used',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text,',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand,',\n",
       " 'interpret,',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language.',\n",
       " 'NLP',\n",
       " 'has',\n",
       " 'many',\n",
       " 'real-world',\n",
       " 'applications,',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation,',\n",
       " 'sentiment',\n",
       " 'analysis,',\n",
       " 'and',\n",
       " 'chatbots.',\n",
       " 'babies,',\n",
       " 'companies']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Lowercasing: Convert all tokens to lowercase.",
   "id": "b67eee62f0bb6eb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:39:18.178732Z",
     "start_time": "2025-09-23T05:39:18.168567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lowercase_tokens = [i.lower() for i in tokens]\n",
    "lowercase_tokens"
   ],
   "id": "694897885a7e4ac9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(nlp)',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics,',\n",
       " 'computer',\n",
       " 'science,',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language.',\n",
       " \"it's\",\n",
       " 'used',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text,',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand,',\n",
       " 'interpret,',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language.',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'real-world',\n",
       " 'applications,',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation,',\n",
       " 'sentiment',\n",
       " 'analysis,',\n",
       " 'and',\n",
       " 'chatbots.',\n",
       " 'babies,',\n",
       " 'companies']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Punctuation Removal: Remove all punctuation marks from the tokens.",
   "id": "d754a77a55500154"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:39:21.509539Z",
     "start_time": "2025-09-23T05:39:21.500682Z"
    }
   },
   "cell_type": "code",
   "source": "print(string.punctuation)",
   "id": "12aadf0363492ba6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T06:00:47.020111Z",
     "start_time": "2025-09-23T06:00:47.011224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleaned_tokens = []\n",
    "\n",
    "for token in lowercase_tokens:\n",
    "    clean_token = ''.join([char for char in token if char not in string.punctuation])\n",
    "    cleaned_tokens.append(clean_token)\n",
    "\n",
    "cleaned_tokens"
   ],
   "id": "a3d53f3440f72c7a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'linguistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'the',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'and',\n",
       " 'human',\n",
       " 'language',\n",
       " 'its',\n",
       " 'used',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'and',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'realworld',\n",
       " 'applications',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'chatbots',\n",
       " 'babies',\n",
       " 'companies']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Stop Word Removal: Remove common stop words (e.g., \"the\", \"is\", \"and\").",
   "id": "2eae6c578a8c0df1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:39:27.360908Z",
     "start_time": "2025-09-23T05:39:27.350936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_words = [\"the\", \"a\", \"an\", \"in\", \"on\", \"at\", \"for\", \"to\", \"of\",\n",
    "            \"and\", \"is\", \"are\", 'but', 'if', 'so']"
   ],
   "id": "1a99cd38acf40eb5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T06:00:51.072514Z",
     "start_time": "2025-09-23T06:00:51.061123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered_tokens = [i for i in cleaned_tokens if i not in stop_words]\n",
    "filtered_tokens"
   ],
   "id": "bf63961edcda4718",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concerned',\n",
       " 'with',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'human',\n",
       " 'language',\n",
       " 'its',\n",
       " 'used',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allowing',\n",
       " 'machines',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'realworld',\n",
       " 'applications',\n",
       " 'including',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'chatbots',\n",
       " 'babies',\n",
       " 'companies']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Stemming: Reduce words to their root form using a simple algorithm.",
   "id": "c085eab7bcb42af6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:44:09.133847Z",
     "start_time": "2025-09-23T05:44:09.125436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Common suffix rules (ordered by priority)\n",
    "suffix_rules = [\n",
    "    ('ational', 'ate'), ('tional', 'tion'),\n",
    "    ('enci', 'ence'), ('anci', 'ance'),\n",
    "    ('izer', 'ize'), ('ator', 'ate'),\n",
    "    ('alli', 'al'), ('entli', 'ent'), ('eli', 'e'),\n",
    "    ('ousli', 'ous'),\n",
    "    ('ization', 'ize'), ('ation', 'ate'),\n",
    "    ('fulness', 'ful'), ('ousness', 'ous'), ('iveness', 'ive'),\n",
    "    ('ing', ''), ('ed', ''), ('er', ''), ('est', ''), ('ly', ''),\n",
    "    ('ment', ''), ('ness', ''), ('tion', ''), ('sion', ''),\n",
    "    ('able', ''), ('ible', ''), ('al', ''), ('ful', ''),\n",
    "    ('ous', ''), ('ive', ''), ('ic', ''),\n",
    "    ('ies', 'y'), ('s', ''),\n",
    "]"
   ],
   "id": "69d49b505e89dd8b",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T06:00:57.421761Z",
     "start_time": "2025-09-23T06:00:57.408735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stemmed_tokens = []\n",
    "for token in filtered_tokens:\n",
    "    if len(token) > 3:\n",
    "        stemmed = token\n",
    "        for suffix, replacement in suffix_rules:\n",
    "            if stemmed.endswith(suffix):\n",
    "                stemmed = stemmed[:-len(suffix)] + replacement\n",
    "                break\n",
    "\n",
    "        if len(stemmed) >= 2:\n",
    "            stemmed_tokens.append(stemmed)\n",
    "        else:\n",
    "            stemmed_tokens.append(token)\n",
    "    else:\n",
    "        stemmed_tokens.append(token)\n",
    "\n",
    "stemmed_tokens"
   ],
   "id": "73084b5cc54afbae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natur',\n",
       " 'language',\n",
       " 'process',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistic',\n",
       " 'comput',\n",
       " 'science',\n",
       " 'artifici',\n",
       " 'intelligence',\n",
       " 'concern',\n",
       " 'with',\n",
       " 'interaction',\n",
       " 'between',\n",
       " 'computer',\n",
       " 'human',\n",
       " 'language',\n",
       " 'its',\n",
       " 'us',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allow',\n",
       " 'machine',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'realworld',\n",
       " 'application',\n",
       " 'includ',\n",
       " 'machine',\n",
       " 'translate',\n",
       " 'senti',\n",
       " 'analysi',\n",
       " 'chatbot',\n",
       " 'baby',\n",
       " 'company']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 6. lemmatization: map common words to their base form (e.g., \"is\" -> \"be\", \"are\" -> \"be\").",
   "id": "91df98a3398132db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T05:57:41.797439Z",
     "start_time": "2025-09-23T05:57:41.790908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lemma_dict = {\n",
    "    'am': 'be', 'is': 'be', 'are': 'be', 'was': 'be', 'were': 'be', 'been': 'be', 'being': 'be',\n",
    "    'better': 'good', 'best': 'good', 'worse': 'bad', 'worst': 'bad',\n",
    "\n",
    "    \"allowing\": 'allow',\n",
    "    'including': 'include',\n",
    "    \"processing\": 'process',\n",
    "    'used': 'use' ,\n",
    "    'concerned': 'concern',\n",
    "}"
   ],
   "id": "32985e7bf18c798c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T06:01:02.536968Z",
     "start_time": "2025-09-23T06:01:02.525224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lemmatized_tokens = []\n",
    "for token in filtered_tokens:\n",
    "    if token in lemma_dict:\n",
    "        lemmatized_tokens.append(lemma_dict[token])\n",
    "    else:\n",
    "        lemmatized_tokens.append(token)\n",
    "\n",
    "lemmatized_tokens"
   ],
   "id": "a2cceb3a3c7aeaf8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'process',\n",
       " 'nlp',\n",
       " 'subfield',\n",
       " 'linguistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " 'concern',\n",
       " 'with',\n",
       " 'interactions',\n",
       " 'between',\n",
       " 'computers',\n",
       " 'human',\n",
       " 'language',\n",
       " 'its',\n",
       " 'use',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'allow',\n",
       " 'machines',\n",
       " 'understand',\n",
       " 'interpret',\n",
       " 'manipulate',\n",
       " 'human',\n",
       " 'language',\n",
       " 'nlp',\n",
       " 'has',\n",
       " 'many',\n",
       " 'realworld',\n",
       " 'applications',\n",
       " 'include',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'chatbots',\n",
       " 'babies',\n",
       " 'companies']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
